# Scheduling (2)

## 스레드 스케줄링
* 실제로 OS에서는 프로세스 단위가 아닌 스레드 단위가 스케줄링됨
* 유저 레벨 스레드와 커널 레벨 스레드를 스케줄링하는 방법에 차이가 존재

### Process Contention Scope
* 유저 레벨 스레드는 커널 스레드에 다대일 매핑되어 스케줄됨
* 여러 스레드를 포함하는 하나의 프로세스가 하나의 CPU 코어에 할당됨
    * 프로세스 내의 스레드 간 CPU 코어를 경쟁

### System Contention Scope
* 커널 레벨 스레드를 스케줄
* 각 스레드를 서로 다른 CPU 코어에 할당할 수 있음
    * 커널이 커널 레벨 스레드를 인지하고 관리하므로 가능
    * 유저 레벨 스레드에 비해 동시성이 높은 스케줄 가능

<br/>

## 멀티프로세서 스케줄링
* 현대 컴퓨터 시스템은 여러 CPU를 사용함
    * 여러 개의 CPU
    * 멀티코어 CPU
    * 멀티스레드 코어
    * NUMA 시스템 등

### Symmetric vs Asymmetric 멀티프로세싱
* `symmetric` : 각 코어의 기능이 동일함
    * 각 프로세서가 독립적으로 스케줄링 가능
    1. 모든 코어가 공통된 준비 큐를 사용할 경우 같은 스레드를 사용하는 경쟁 조건을 방지해야 함
    2. 대신 코어 별로 큐를 따로 사용하면 편리. 부하를 균등하게 하는 균형 알고리즘이 필요
* `asymmetric` : 각 코어가 다른 기능을 수행함

### 멀티코어 스케줄링
#### Memory Stall
* 프로세서가 메모리에 비해 월등히 빠르기 때문에, 메모리 데이터 접근 시 많은 시간 **기다림**
* **cache miss** 발생 시 메모리에 접근해야 함

#### Multithreaded Core (CMT, chip multithreading)
* 메모리 대기를 방지하기 위해 하나의 코어가 여러 스레드를 처리하도록 함
    * 스레드가 memory stall로 중단되면, 다른 스레드로 전환
    * 즉, 코어가 여러 개의 하드웨어 스레드를 가지고 있음
* OS의 입장에서는 각 코어의 하드웨어 스레드를 논리적인 CPU로 보고 스레드를 스케줄링함

#### Coarse-grained vs Fine-grained
* `coarse-grained`
    * 처리가 오래 걸리는 이벤트가 발생할 때 스레드를 교환
    * 스레드 문맥 교환 비용이 크다
* `fine-grained`
    * 세밀한 단위로 스레드를 교환
    * 스레드 문맥 교환 비용이 적음. 스레드 교환 회로를 칩 디자인이 포함

#### Two Level 스케줄링
1. 소프트웨어 스레드가 실행될 하드웨어 스레드를 스케줄
    * FCFS 등 OS에서 수행하는 스케줄링
2. 코어에서 실행할 하드웨어 스레드를 스케줄
    * 각 하드웨어 스레드는 같은 코어에서 실행되므로 캐시 등 하드웨어 공유


### Load Balancing
* 코어의 **부하를 균등**하게 유지해 멀티프로세싱의 이점을 활용
* 각 코어가 공통된 준비 큐를 가지는 경우 작업 분배 알고리즘은 굳이 필요하지 않음

#### Push migration & Pull migration
* `push` : 특정 태스크가 모든 프로세서의 부하를 검사해 불균형이 있으면 작업 옮겨줌
* `pull` : 쉬고 있는 프로세서가 부하가 많은 프로세서로부터 작업을 가져옴
* 리눅스의 CFS 스케줄러는 두 기술을 모두 구현함

### Proceessor Affinity
* 캐시 메모리는 최근에 접근한 메모리의 데이터로 채워지게 됨
* 캐시 지역성을 활용하려면, 스레드가 동일한 코어에서 계속 실행되는 것이 유리함
* `soft affinity` : 시스템이 되도록 같은 프로세서에서 실행되게 노력하지만 보장하지는 않음
* `hard affinity` : 시스템 콜을 이용해 프로세스가 실행될 수 있는 프로세서를 지정
* 로드 밸런싱과 선호도는 서로의 이점을 **상쇄**함. 서로 간의 균형을 맞춘 스케줄링이 필요

### Heterogenous 멀티프로세싱 (HMP)
* 각 코어가 기능적으로 다르게 수행될 수 있는 멀티프로세싱
* ARM의 big.LITTLE 구조가 HMP의 예시
    * 고성능 작업을 big 코어에 할당
    * 저성능이지만 오래 실행해야 하는 작업을 little 코어에 할당

<br/>

## 실시간 CPU 스케줄링
* 중요한 실시간 프로세스가 빠르게 스케줄되어 실행되도록
* `soft RTS` : 되도록 중요한 프로세스가 먼저 실행되도록 노력하나 보장하지는 않음
* `hard RTS` : 태스크별 지연 시간 안에 실행되는 것을 보장하는 엄격한 스케줄링

### Minimize Latency
* 이벤트의 종류에 따라 처리해야 하는 지연 허용 시간이 다름

#### Interrupt Latency
* 인터럽트가 발생한 뒤부터 **ISR이 시작**되기까지의 시간
    * 수행 중인 작업을 완료하고 ISR로 문맥을 교환하는 과정을 수행
    * 커널 데이터 수정 완료까지 인터럽트를 무효화하는 것을 고려

#### Dispatch Latency
* 현 프로세스를 멈추고 다른 프로세스를 시작하기까지의 시간
    * 즉, **문맥 교환**에 걸리는 시간
* 선점형 커널을 사용하면 지연 시간을 최소화할 수 있음

### 우선순위 기반 스케줄링
* 작업의 중요도에 따라 우선순위를 부여
* `soft RTS` : 지연 시간 안에 스케줄되어 실행되는 것을 보장하지는 않음
* hard RTS를 위해서는 추가적인 스케줄링 기법을 사용해야 함

### Rate-Monotonic 스케줄링
* 프로세스 CPU 요청 주기가 짧으면 높은 우선순위를 할당
* 주기를 기반으로 정적 우선순위를 부여하는 선점형 스케줄링
* optimal 하지만, CPU 이용률이 떨어질 수 있음

### Earliest Deadline First 스케줄링
* 프로세스의 실행 시간 데드라인을 바탕으로 동적으로 우선순위를 부여
* 프로세스의 데드라인을 알 때 이론적으로 CPU 활용률을 높이는 최적의 스케줄링이 가능

### Proportional Share 스케줄링
* 각 태스크가 총 시간을 나누어 할당받아 실행됨
* 새로운 태스크가 진입 시 충분한 시간을 할당할 수 없다면 deny

### POSIX RTS
* 동일 우선순위 내에서 FIFO 혹은 RR 스케줄링 사용

<br/>

## 스케줄링 알고리즘의 평가
* 스케줄링 알고리즘의 성능을 평가하는 알고리즘
* CPU 활용률, 프로세스의 대기 시간, throughput 등 여러 지표 활용


### Deterministic Modeling
* 미리 정의된 작업 부하를 각 스케줄링 알고리즘 별로 실행해 성능을 평가
* 동일한 프로그램을 반복 실행할 수 있고 정확한 값이 입력될 때만 사용 가능

### Queueing Models
* 이용률, 평균 큐 길이, 평균 대기 시간 등의 통계 자료를 수집해 성능을 평가
* CPU 및 IO burst의 분포, 프로세스가 도착하는 시간의 분포 등을 활용해 계산

### Simulations
* 정확한 알고리즘의 평가를 위해 컴퓨터 시스템을 소프트웨어로 가상화
1. 확률 분포에 따른 난수 발생기로 이벤트를 생성해 시뮬레이션
2. 실제 시스템을 모니터링한 Trace File 이용해 이벤트를 기록해 시뮬레이션에 이용
* 시뮬레이션 수행 및 데이터 수집의 비용이 크다는 단점 존재

### Implementation
* 더 높은 정확도를 위해 실제 시스템에 실제 스케줄링 알고리즘 삽입해 평가
* OS의 코드를 변형하고, 데이터 수집 등 비용이 크다는 단점 존재